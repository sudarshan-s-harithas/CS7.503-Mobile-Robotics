{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e806d4",
   "metadata": {},
   "source": [
    "# Assignment - 2: Data Representation and Point Cloud Operations\n",
    "\n",
    "Team Name: Sudarshan_Rishabh \\\n",
    "Roll number:  2021701008 2021701030"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e42e4d4",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "- Code must be written in Python in Jupyter Notebooks. We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment.\n",
    "- Save all your results in ```results/<question_number>/<sub_topic_number>/```\n",
    "- The **References** section provides you with important resources to solve the assignment.\n",
    "- Make sure your code is modular since you may need to reuse parts for future assignments.\n",
    "- Answer the descriptive questions in your own words with context & clarity. Do not copy answers from online resources or lecture notes.\n",
    "- The **deadline** for this assignment is on 26/09/2021 at 11:55pm. Please note that there will be no extensions.\n",
    "- Plagiarism is **strictly prohibited**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ccd58",
   "metadata": {},
   "source": [
    "# Submission Instructions\n",
    "\n",
    "1. Make sure your code runs without any errors after reinitializing the kernel and removing all saved variables.\n",
    "2. After completing your code and saving your results, zip the folder with name as ``Team_<team_name>_MR2021_Assignment_<assignment_number>.zip``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40d245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85262a",
   "metadata": {},
   "source": [
    "# Introduction to types of Transformations and Homogeneous coordinates\n",
    "\n",
    "In robotics applications, it is inevitable to keep track of the frames of multiple objects/worlds. These frames can be transformations from one coordinate frame to the other. **Homogeneous coordinates** help in keeping track of various coordinate frames and allow performing composition of various transforms. We will first try to understand between types of transformations and their invariant properties.\n",
    "1. What is the difference between Affine, Similarity, and Euclidean transform? What are the invariant properities of each type of transform?\\\n",
    "\n",
    "Eucledian transform is subset of Similarity transform, and Similarity transform is subset of Affine transform.\\\n",
    "Eucledian transform:- Translation + Rotation. (Preserves Angles and Distances)\\\n",
    "Similarity transform:- Eucledian + Uniform Scaling. (Preserves Angles) \\\n",
    "Affine transform:- Similarity + Scaling + Reflection + Shear. (Preserves parallel lines)\\\n",
    "Invariant property:- lines and parallelism is preserved in all. Affine transformation does not necessarily preserve angles between lines or distances between points, though it does preserve ratios of distances between points lying on a straight line. \\\n",
    "Ref:- https://www.cs.tau.ac.il/~dcor/Graphics/cg-slides/trans3d.pdf \\\n",
    "Ref:- https://www.cs.toronto.edu/~kyros/courses/418/Lectures/lecture.2010f.02.pdf \\\n",
    "\n",
    "\n",
    "\n",
    "2. Watch this [video](https://www.youtube.com/watch?v=PvEl63t-opM) to briefly understand homogeneous coordinates. What are points at infinity? What type of transformation can you apply to transform a point from infinity to a point that is not at infinity? \\\n",
    "\n",
    "Answer: \\\n",
    "We use projective geometry to depict a 3-D scenes on 2-D surfaces.\n",
    "In Eucledian geometry, parallel lines donâ€™t meet in a point. But Projective geometry, all lines intersect. \n",
    "The points at infinity are the points which are added to the space to get the projective completion. \n",
    "Eg. Projection of two paralleel railway tracks on projective plane. Ideal points on the projective plane are located at infinity, and have coordinates of the form $(x_1, x_2, 0)$. \n",
    "\\\n",
    "https://pointatinfinityblog.wordpress.com/2016/04/11/points-at-infinity-i-projective-geometry/ \\\n",
    "https://www.ipb.uni-bonn.de/html/teaching/3dcs-ge-2021/stachniss/2020-3dcs-02-homogeneous-coords-4.pdf \\\n",
    "\\\n",
    "Projective transformations are more general than affine transformations because the fourth row does not have to contain 0, 0, 0 and 1. So, we can use Projective transformations for point at infinity.\\\n",
    "P is projective transfomation  and H is affine transformatio matrix. \\\n",
    "$$ P =\\left[\\begin{array}{rrrr}p_{11} & p_{12} &  p_{13} & p_{14} \\\\ p_{21} & p_{22} & p_{23} & p_{24} \\\\\n",
    "    p_{31} & p_{32} & p_{33} & p_{34} \\\\\n",
    "    p_{41} & p_{42} & p_{43} & p_{44}   \\end{array}\\right] \n",
    "$$ \n",
    "$$ H = \\left[\\begin{array}{rrrr}a_{11} & a_{12} &  a_{13} & a_{14} \\\\ a_{21} & a_{22} & a_{23} & a_{24} \\\\\n",
    "    a_{31} & a_{32} & a_{33} & a_{34} \\\\\n",
    "    0 & 0 & 0 & 1  \\end{array}\\right] \n",
    "$$ \\\n",
    "Ref: https://pages.mtu.edu/~shene/COURSES/cs3621/NOTES/geometry/geo-tran.html\n",
    "\n",
    "\n",
    "\n",
    "3. Using homogeneous coordinates we can represent different types of transformation as point transforms vs. frame transforms. Concatenation of transforms (whether you post multiply transformation matrices or pre-multiply transformation matrices) depends on the problem and how you are viewing it. Try to understand the difference between frame vs. point transformations from this [video](https://youtu.be/Za7Sdegf8m8?t=1834). Let's assume that our camera and world frames are coinciding with each other. We need to estimate the camera to world **frame** transformation matrix after applying the transformations defined below in terms of $T_i$.We apply **frame** transform to move the camera in the world in the following order:\n",
    "    1. $T_1$ from the camera coordinate frame.\n",
    "    2. $T_2$ from the world coordinate frame.\n",
    "    3. $T_3$ from the world coordinate frame.\n",
    "    4. $T_4$ from the camera coordinate frame.\n",
    "    5. $T_5$ from the camera coordinate frame.\\\n",
    "\n",
    "Answer: \\\n",
    "$(T_3 * T_2 * T_i * T_1 * T_4 * T_5)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f08d84",
   "metadata": {},
   "source": [
    "# Visualise the Data\n",
    "\n",
    "Point clouds are a collection of points that represent a 3D shape or feature. Each point has its own set of X, Y and Z coordinates and in some cases additional attributes. A popular way to obtain this is by photogrammetry, though here we will use LiDAR data.\n",
    "\n",
    "LiDAR is a remote sensing process which collects measurements used to create 3D models and maps of objects and environments. Using ultraviolet, visible, or near-infrared light, LiDAR gauges spatial relationships and shapes by measuring the time it takes for signals to bounce off objects and return to the scanner.\n",
    "\n",
    "1. Download the data from [here](https://iiitaphyd-my.sharepoint.com/:f:/g/personal/venkata_surya_students_iiit_ac_in/EnYAMaTVIhJItzKYqtahE30BRKB6p6UfHN3TyJzvo6Mw0g?e=PegWds). It contains the LIDAR sensor output and odometry information per frame.\n",
    "\n",
    "    The .bin files contain the 3D point cloud captured by the LIDAR in this format - x, y, z, and reflectance. \n",
    "\n",
    "    The odometry information is given in the `odometry.txt` file, which is a 12 element vector. Reshape each of the first 77 rows to a 3x4 matrix to obtain the pose.\n",
    "    \n",
    "\n",
    "2. Obtain the point cloud from this and visualise for 1-2 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64632556",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# 1a .Reading the point cloud and making it into n*3 matrix\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "path_to_pcd = os.path.join(fileDir, 'data/LiDAR')\n",
    "\n",
    "path_to_files = sorted(os.listdir(path_to_pcd)) \n",
    "# print( path_to_files)\n",
    "\n",
    "for count, pcd_file in enumerate(path_to_files): \n",
    "#     print(count)\n",
    "    complete_path = os.path.join( path_to_pcd , pcd_file )\n",
    "    bin_pcd = np.fromfile(complete_path , dtype=np.float32) #single array\n",
    "    points = bin_pcd.reshape((-1, 4))[:, 0:3]  #make an n*3 matrix and remove last column\n",
    "#     print((points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ae7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b .Reading odometry.txt and converting into 3*4 matrix\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "\n",
    "def load_poses(path):\n",
    "    # odometry_data = np.loadtxt(path)\n",
    "    odometry_data = genfromtxt(path, delimiter=',')\n",
    "    return odometry_data\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "odometry_file_path = os.path.join(fileDir, 'data/odometry.csv')\n",
    "\n",
    "# odometry_file_path =  \"/home/rishabh/notebook/MR2021-Assignment-2/data/odometry.csv\"\n",
    "odometry = load_poses( odometry_file_path)\n",
    "\n",
    "# print(odom)\n",
    "\n",
    "T_current_frame = np.zeros( (3, 4))\n",
    "for count, odom in enumerate(odometry):\n",
    "    T_current_frame[0:3 , 0:4] = np.reshape( odom , (3,4))\n",
    "    \n",
    "#     print(count)\n",
    "#     print(T_current_frame)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "directed-termination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  0\n",
      "Count:  1\n",
      "Count:  2\n"
     ]
    }
   ],
   "source": [
    "# 2. Obtain the point cloud from this and visualise for 1-2 frames.\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "path_to_pcd = os.path.join(fileDir, 'data/LiDAR')\n",
    "path_to_files = sorted(os.listdir(path_to_pcd)) \n",
    "# print( path_to_files)\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "for count, pcd_file in enumerate(path_to_files): \n",
    "    print(\"Count: \", count)\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    \n",
    "    complete_path = os.path.join( path_to_pcd , pcd_file )\n",
    "    bin_pcd = np.fromfile(complete_path , dtype=np.float32) #single array\n",
    "    points = bin_pcd.reshape((-1, 4))[:, 0:3]  #make an 3*4 matrix and remove last column\n",
    "    \n",
    "    o3d_pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(points))\n",
    "    vis.add_geometry(o3d_pcd)\n",
    "    vis.run()\n",
    "    \n",
    "    if count == 2:\n",
    "        break\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-riverside",
   "metadata": {},
   "source": [
    "# Transform \n",
    "\n",
    "The point cloud obtained is with respect to the LiDAR frame. The poses however, are in the camera frame. If we want to combine the point clouds from various frames, we need to bring them to the camera frame. \n",
    "\n",
    "1. Refer to the image below and apply the required transformation to the point cloud. \n",
    "\n",
    "2. Then, register all point clouds into a common reference frame and visualise it (Open3D). It is helpful to use homogeneous coordinates to keep track of the different frames.\n",
    "\n",
    "3. Write a function to transform the registered point cloud from the world to the $i^{th}$ camera frame, wherein $i$ is the input to the function.\n",
    "\n",
    "4. \\[Bonus\\] Move around in the registered point cloud using arrow keys like you would do in a game. For this you will have to regularly transform the entire registered world to your current camera frame and visualize repeatedly. You may choose to avoid visualizing points that are behind the camera in this case as they are not visible from the scene. You may also visualize points at a max depth to make the process easier.\n",
    "\n",
    "![](./img/transform.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7af9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1. apply the required transformation to the point cloud\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "\n",
    "def load_poses(path):\n",
    "    odometry_data = genfromtxt(path, delimiter = ',')\n",
    "    return odometry_data\n",
    "\n",
    "def eul_to_rotm_xyz(a,b,c):\n",
    "    Ma = np.array([[1, 0, 0], [0, np.cos(c), -np.sin(c)], [0, np.sin(c), np.cos(c)]])\n",
    "    Mb = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
    "    Mc = np.array([[np.cos(a), -np.sin(a), 0], [np.sin(a), np.cos(a), 0], [0, 0, 1]])\n",
    "    M1 = np.matmul(Ma,Mb)\n",
    "    M = np.matmul(M1,Mc)\n",
    "    return M\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "odometry_file_path = os.path.join(fileDir, 'data/odometry.csv')\n",
    "odom = load_poses(odometry_file_path)\n",
    "\n",
    "path_to_pcd = os.path.join(fileDir, 'data/LiDAR')\n",
    "path_to_files = sorted(os.listdir(path_to_pcd)) \n",
    "\n",
    "R = eul_to_rotm_xyz(np.pi/2, 0, np.pi/2) # 3*3 matrix only rotation\n",
    "\n",
    "for pcd_file in path_to_files:\n",
    "    complete_path = os.path.join( path_to_pcd , pcd_file )\n",
    "    bin_pcd = np.fromfile(complete_path , dtype=np.float32)\n",
    "    \n",
    "    points_current_frame = bin_pcd.reshape((-1, 4))[:, 0:3] # n*3 matrix\n",
    "    points_current_frame = (R@(points_current_frame.T)).T\n",
    "    \n",
    "# points_current_frame are points observed in camera frame.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09190020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: The GLFW library is not initialized\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# 2. register all point clouds into a common reference frame and visualise it \n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "def eul_to_rotm_xyz(a,b,c):\n",
    "    Ma = np.array([[1, 0, 0], [0, np.cos(c), -np.sin(c)], [0, np.sin(c), np.cos(c)]])\n",
    "    Mb = np.array([[np.cos(b), 0, np.sin(b)], [0, 1, 0], [-np.sin(b), 0, np.cos(b)]])\n",
    "    Mc = np.array([[np.cos(a), -np.sin(a), 0], [np.sin(a), np.cos(a), 0], [0, 0, 1]])\n",
    "    M1 = np.matmul(Ma,Mb)\n",
    "    M = np.matmul(M1,Mc)\n",
    "    return M\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "world_points = o3d.geometry.PointCloud()\n",
    "\n",
    "pose_count = 9\n",
    "all_points = np.array( [[ 0,0,0]])\n",
    "\n",
    "T_world = np.array( [  [  1 ,0,0,0 ] , \n",
    "                    [0 ,1 ,0 ,0 ] , \n",
    "                    [0,0,1,0] , \n",
    "                    [0,0,0,1]  ])\n",
    "\n",
    "T_current_frame = np.array( [  [  1 ,0,0,0 ] , \n",
    "                    [0 ,1 ,0 ,0 ] , \n",
    "                    [0,0,1,0] , \n",
    "                    [0,0,0,1]  ] , dtype ='float32')\n",
    "\n",
    "iter_count = 0\n",
    "for pcd_file in path_to_files:\n",
    "    complete_path = os.path.join( path_to_pcd , pcd_file )\n",
    "    bin_pcd = np.fromfile(complete_path , dtype=np.float32 )\n",
    "\n",
    "    points_current_frame = bin_pcd.reshape((-1, 4))[:, 0:3]\n",
    "\n",
    "    pcd2 = o3d.geometry.PointCloud()\n",
    "    pcd2.points = o3d.utility.Vector3dVector(points_current_frame)\n",
    "    dpcd = pcd2.voxel_down_sample(voxel_size = 0.5)\n",
    "\n",
    "    points_current_frame = np.array(dpcd.points)\n",
    "\n",
    "    R = eul_to_rotm_xyz(np.pi/2, 0, np.pi/2)\n",
    "    R1 = np.eye(4)\n",
    "    R1[:3, :3] = R\n",
    "    points_current_frame = (R@(points_current_frame.T)).T\n",
    "\n",
    "    one = np.ones( ( np.shape( points_current_frame)[0] ,1)  )\n",
    "    points_current_frame = np.append( points_current_frame,  one , axis=1)\n",
    "\n",
    "    T_current_frame[0:3 , 0:4] = np.reshape( odom[pose_count] , (3,4))\n",
    "    update_points = ((T_current_frame)@points_current_frame.T).T\n",
    "\n",
    "    all_points =np.append(all_points  , update_points[:,0:3] , axis= 0)\n",
    "    pose_count +=1\n",
    "    iter_count +=1 \n",
    "\n",
    "world_points.points = o3d.utility.Vector3dVector(all_points)\n",
    "world_points = world_points.voxel_down_sample(voxel_size = 0.05)\n",
    "o3d.visualization.draw_geometries([world_points])\n",
    "\n",
    "o3d.io.write_point_cloud('World_pts.pcd' , world_points)\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14d9e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enter Frame index3\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: The GLFW library is not initialized\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# 3. a function to transform the registered point cloud from the world to the ith camera frame\n",
    "\n",
    "# RUN IN SEQUENCE\n",
    "\n",
    "frame_index_i = int ( input(\" Enter Frame index\"))\n",
    "\n",
    "camera_pose_at_frame_index_i = np.array( [  [  1 ,0,0,0 ] , \n",
    "\t\t\t\t\t[0 ,1 ,0 ,0 ] , \n",
    "\t\t\t\t\t[0,0,1,0] , \n",
    "\t\t\t\t\t[0,0,0,1]  ] , dtype ='float32')\n",
    "\n",
    "camera_pose_at_frame_index_i[0:3, 0:4] =  np.reshape( odom[frame_index_i] , (3,4))\n",
    "\n",
    "one_arr =  np.ones( ( np.shape(all_points)[0] , 1 ) )\n",
    "all_points_copy = np.append( all_points , one_arr , axis =1) \n",
    "all_points_at_frame_i = ((camera_pose_at_frame_index_i)@all_points_copy.T).T\n",
    "\n",
    "reference_coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame( size=20, origin= [  camera_pose_at_frame_index_i[0][3] , camera_pose_at_frame_index_i[1][3] , camera_pose_at_frame_index_i[2][3] ])\n",
    "\n",
    "world_points.points = o3d.utility.Vector3dVector(all_points_at_frame_i[:, 0:3])\n",
    "o3d.visualization.draw_geometries([world_points , reference_coordinate])\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3dc5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "RIGHT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "LEFT\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "FORWARD\n",
      "Roll - \n",
      "Roll - \n",
      "YAW +\n",
      "Pitch - \n",
      "DOWN\n",
      "DOWN\n",
      "DOWN\n",
      "UP\n",
      "UP\n",
      "UP\n",
      "Roll - \n",
      "Roll - \n",
      "YAW -\n",
      "YAW -\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_388732/2166058579.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mfpsclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_refrence_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Bonus\n",
    "\n",
    "import pygame\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "pygame.init()\n",
    "fps=7\n",
    "fpsclock=pygame.time.Clock()\n",
    "sur_obj=pygame.display.set_mode((400,300))\n",
    "pygame.display.set_caption(\"Keyboard_Input\")\n",
    "White=(255,255,255)\n",
    "p1=10\n",
    "p2=10\n",
    "step=5\n",
    "opp = 1\n",
    "x_mov,y_mov,z_mov = 1,1,1 \n",
    "R = np.eye(3)\n",
    "x_total, y_total, z_total, yaw = 0,0,0,0\n",
    "theta = 0\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "complete_path = 'World_pts.pcd'\n",
    "global pcd\n",
    "pcd = o3d.io.read_point_cloud(complete_path)\n",
    "pcd = pcd.voxel_down_sample(voxel_size = 0.1)\n",
    "\n",
    "all_pts = np.array( pcd.points)\n",
    "\n",
    "one = np.ones( ( np.shape( all_pts)[0] ,1)  )\n",
    "all_pts = np.append( all_pts,  one , axis=1)\n",
    "\n",
    "H = np.array( [  [  1 ,0,0,0 ] , \n",
    "                    [0 ,1 ,0 ,0 ] , \n",
    "                    [0,0,1,0] , \n",
    "                    [0,0,0,1]  ] , dtype ='float32')\n",
    "\n",
    "global world_refrence_frame \n",
    "world_refrence_frame= o3d.geometry.TriangleMesh.create_coordinate_frame( size=20, origin= [  0,0,0 ])\n",
    "global reference_coordinate \n",
    "reference_coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame( size=20, origin= [  0,0,0 ])\n",
    "\n",
    "global all_pts_point_cloud \n",
    "all_pts_point_cloud = o3d.geometry.PointCloud()\n",
    "all_pts_point_cloud = pcd \n",
    "\n",
    "def perform_transformation(R,tx,ty,tz):\n",
    "    global reference_coordinate \n",
    "    global pcd\n",
    "    reference_coordinate = reference_coordinate.translate((tx, ty , tz))\n",
    "\n",
    "    for i in range(5):\n",
    "        reference_coordinate.rotate(R)\n",
    "        vis.update_geometry(reference_coordinate)\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "\n",
    "    H[0:3, 0:3] = R\n",
    "    H[0][3] = tx\n",
    "    H[1][3] =ty \n",
    "    H[2][3] = tz\n",
    "\n",
    "    pts = (H@(all_pts.T)).T \n",
    "    all_pts_point_cloud.points = o3d.utility.Vector3dVector(pts[: , 0:3]) \n",
    "    vis.update_geometry(all_pts_point_cloud)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "vis.add_geometry(all_pts_point_cloud)\n",
    "# vis.update_geometry(pcd)\n",
    "vis.poll_events()\n",
    "vis.update_renderer()\n",
    "\n",
    "while True:\n",
    "    sur_obj.fill(White)\n",
    "    pygame.draw.rect(sur_obj, (255,0,0), (p1, p2, 70, 65))\n",
    "    for eve in pygame.event.get():\n",
    "        if eve.type==pygame.QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "\n",
    "    key_input = pygame.key.get_pressed()   \n",
    "    if key_input[pygame.K_LEFT]:\n",
    "        p1 -= step\n",
    "        print(\"LEFT\")\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,0,-1,0)\n",
    "\n",
    "    if key_input[pygame.K_RIGHT]:\n",
    "        p1 += step\n",
    "        print(\"RIGHT\")\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,0,1,0)\n",
    "    \n",
    "    if key_input[pygame.K_UP]:\n",
    "        p2 -= step\n",
    "        print(\"FORWARD\")\n",
    "        x_mov = 1 \n",
    "        x_total = x_total + x_mov #in world_frame\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,1,0,0)\n",
    "\n",
    "    if key_input[pygame.K_DOWN]:\n",
    "        p2 += step\n",
    "        print(\"BACKWARD\")\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,-1,0,0)\n",
    "    \n",
    "    if key_input[pygame.K_KP9]: #keypad 9\n",
    "        print(\"YAW +\")\n",
    "        yaw =  1  #degree\n",
    "        theta = np.deg2rad(yaw)\n",
    "        R = np.array( [[np.cos(theta),-np.sin(theta),         0], \n",
    "              [np.sin(theta),np.cos(theta), 0], \n",
    "              [   0,            0,          1]])\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,x_total,y_total,z_total)\n",
    "\n",
    "    if key_input[pygame.K_KP7]: #keypad 7\n",
    "        print(\"YAW -\")\n",
    "        yaw =  -1  #degree\n",
    "        theta = np.deg2rad(yaw)\n",
    "        R = np.array( [[np.cos(theta),-np.sin(theta),         0], \n",
    "              [np.sin(theta),np.cos(theta), 0], \n",
    "              [   0,            0,          1]])\n",
    "\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,x_total,y_total,z_total)\n",
    "        continue\n",
    "    \n",
    "    if key_input[pygame.K_KP8]: #keypad 8\n",
    "        \n",
    "        print(\"Roll - \")\n",
    "        roll = -1 \n",
    "        roll = np.deg2rad(roll)\n",
    "        R = np.array( [ [ np.cos(roll) ,  0,   np.sin(roll) ] , \n",
    "                      [0,1,0] , \n",
    "                     [ -np.sin(roll) ,  0 , np.cos(roll)   ]  ] )\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,x_total,y_total,z_total)\n",
    "        continue \n",
    "\n",
    "    if key_input[pygame.K_KP0]: #keypad 0\n",
    "        \n",
    "        print(\"Pitch - \")\n",
    "        pitch = -1 \n",
    "        pitch = np.deg2rad(pitch)\n",
    "        R = np.array( [ [ np.cos(pitch) ,  -np.sin(pitch) ,  0 ] , \n",
    "                      [np.sin(pitch),np.cos(pitch),0] , \n",
    "                     [ 0 ,  0 , 1  ]  ] )\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,x_total,y_total,z_total)\n",
    "        continue    \n",
    "        \n",
    "    if key_input[pygame.K_KP5]: #keypad 5\n",
    "        p2 -= step\n",
    "        print(\"UP\")\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,0,0,1)\n",
    "     \n",
    "    if key_input[pygame.K_KP2]: #keypad 2\n",
    "        p2 -= step\n",
    "        print(\"DOWN\")\n",
    "        vis.add_geometry(reference_coordinate)\n",
    "        vis.add_geometry(world_refrence_frame)\n",
    "        perform_transformation(R,0,0,-1)\n",
    "\n",
    "    pygame.display.update()\n",
    "    fpsclock.tick(fps)\n",
    "    vis.add_geometry(world_refrence_frame)\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-divorce",
   "metadata": {},
   "source": [
    "## Occupancy Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-discussion",
   "metadata": {},
   "source": [
    "Occupancy grid maps are discrete fine grain grid maps. These maps can be either 2-D or 3-D. Each cell in the occupancy grid map contains information on the physical objects present in the corresponding space. Since these maps shed light on what parts of the environment are occupied, and what is not, they are really useful for path planning and navigation.\n",
    "\n",
    "Occupancy grid maps are probabilistic in nature due to noisy measurements. Each cell can have three states: Occupied, unoccupied, and unknown. For the purpose of this assignment, you can ignore the unknown and work in a binary setting where 1 is occupied and 0 is unoccupied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-display",
   "metadata": {},
   "source": [
    "1. The task here is to create an occupancy map for each LiDAR scan. You do not need to apply bayesian update rules here, just keep it simple. \n",
    "\n",
    "2. Now, using the *registered* point cloud, generate occupancy maps for each frame. What difference do you expect to see between the two methods?\n",
    "\n",
    "You can mark a cell as occupied based on a threshold of how many different z values are there for a particular (x,y) cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452e7b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. create an occupancy map for each LiDAR scan.\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from numpy import genfromtxt\n",
    "\n",
    "def load_poses(path):\n",
    "    odometry_data = genfromtxt(path, delimiter = ',')\n",
    "    return odometry_data\n",
    "\n",
    "\n",
    "def get_limits_of_map(coordinates):\n",
    "    X = coordinates[:, 0 ]\n",
    "    Y = coordinates[: ,1]\n",
    "    Z = coordinates[: ,2]\n",
    "    xmin = np.amin(X)\n",
    "    xmax = np.amax(X)\n",
    "    ymin = np.amin(Y)\n",
    "    ymax = np.amax(Y)\n",
    "    return xmin , ymin , xmax ,ymax\n",
    "\n",
    "def set_grid_resolution_and_sub_resolution(xmin , ymin , xmax, ymax ):\n",
    "    pts = 1000\n",
    "    sub_pts = 3\n",
    "    xres =  (xmax -xmin)/pts\n",
    "    yres = ( ymax - ymin)/pts \n",
    "    res = [ xres , yres]\n",
    "    return res , sub_pts\n",
    "\n",
    "def get_point_set( Q , points_current_frame, threshold):\n",
    "    vaild_set = np.array([0 , 0 , 0])\n",
    "    for pts in points_current_frame:\n",
    "        # print(Q)\n",
    "        # print(pts)\n",
    "        L1 = np.sum(np.abs( Q - pts[0:2]))\n",
    "        # print(L1)\n",
    "        z_count = 0\n",
    "        if( L1 < threshold/2 ):\n",
    "            print(pts)\n",
    "            if(pts[2] > -1.0):\n",
    "                z_count +=1 \n",
    "            if(z_count > 5):\n",
    "                return True \n",
    "\n",
    "            \n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "odometry_file_path = os.path.join(fileDir, 'data/odometry.csv')\n",
    "odom = load_poses(odometry_file_path)\n",
    "\n",
    "path_to_pcd = os.path.join(fileDir, 'data/LiDAR')\n",
    "path_to_files = sorted(os.listdir(path_to_pcd)) \n",
    "\n",
    "complete_path = os.path.join( path_to_pcd , path_to_files[0] )\n",
    "bin_pcd = np.fromfile(complete_path , dtype=np.float32)\n",
    "points_current_frame = bin_pcd.reshape((-1, 4))[:, 0:3]\n",
    "xmin , ymin , xmax, ymax =   get_limits_of_map( points_current_frame)\n",
    "res, sub_res = set_grid_resolution_and_sub_resolution(xmin , ymin , xmax, ymax )\n",
    "height_counter = np.zeros( ( 1001 , 1001 ))\n",
    "Occ_map = np.zeros( ( 1001 , 1001 ))\n",
    "height_counter = np.zeros( ( 1001 , 1001 ))\n",
    "Occ_map = np.zeros( ( 1001 , 1001 ))\n",
    "\n",
    "for pt in points_current_frame:\n",
    "    x = int( (pt[0] -xmin )/ res[0]) \n",
    "    y = int( (pt[1] -ymin)/ res[1])\n",
    "    if( pt[2] > -1):\n",
    "        height_counter[x][y] +=1\n",
    "    if( height_counter[x][y] > 3): # If the number of Z values is greater than 3 then consider obstacle \n",
    "        Occ_map[x][y] = 255 ## white color represents an obstacle \n",
    "\n",
    "# print(Occ_map)\n",
    "# plt.imshow(Occ_map)\n",
    "# plt.show()\n",
    "cv2.imshow('Map', height_counter)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7d1fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. using the registered point cloud, generate occupancy maps for each frame\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "complete_path = 'World_pts.pcd'\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(complete_path)\n",
    "points_current_frame = np.asarray( pcd.points)\n",
    "xmin , ymin , xmax, ymax =   get_limits_of_map( points_current_frame)\n",
    "res, sub_res = set_grid_resolution_and_sub_resolution(xmin , ymin , xmax, ymax )\n",
    "height_counter = np.zeros( ( 1001 , 1001 ))\n",
    "Occ_map = np.zeros( ( 1001 , 1001 ))\n",
    "\n",
    "for pt in points_current_frame:\n",
    "    x = int( (pt[0] - xmin ) / res[0])\n",
    "    y = int( (pt[1] -ymin)  / res[1])\n",
    "    if( pt[2] > -1):\n",
    "        height_counter[x][y] +=1\n",
    "    if( height_counter[x][y] > 3):\n",
    "        Occ_map[x][y] = 255\n",
    "\n",
    "# print(Occ_map)\n",
    "cv2.imshow('Map', Occ_map)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf90a61",
   "metadata": {},
   "source": [
    "The second method has a large number of points and is a dense map, whereas the first method is shown only for frame one has few points and is less dense. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
