{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c84b911",
   "metadata": {},
   "source": [
    "# Assignment-1: Transformations and representations\n",
    "\n",
    "Team Name: Sudarshan_Rishabh\n",
    "\n",
    "Roll number: 2021701008 2021701030"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07191065",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "- Code must be written in Python in Jupyter Notebooks. We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment. See `Set Up` for detailed step-by-step instructions about the installation setup.\n",
    "- Save all your results in ```results/<question_number>/<sub_topic_number>/```\n",
    "- The **References** section provides you with important resources to solve the assignment.\n",
    "- For this assignment, you will be using Open3D extensively. Refer to [Open3D Documentation](http://www.open3d.org/docs/release/): you can use the in-built methods and **unless explicitly mentioned**, don't need to code from scratch for this assignment. \n",
    "- Make sure your code is modular since you may need to reuse parts for future assignments.\n",
    "- Answer the descriptive questions in your own words with context & clarity. Do not copy answers from online resources or lecture notes.\n",
    "- The **deadline** for this assignment is on 11/09/2021 at 11:55pm. Please note that there will be no extensions.\n",
    "- Plagiarism is **strictly prohibited**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40094ecc",
   "metadata": {},
   "source": [
    "# Submission Instructions\n",
    "\n",
    "1. Make sure your code runs without any errors after reinitializing the kernel and removing all saved variables.\n",
    "2. After completing your code and saving your results, zip the folder with name as ``Team_<team_name>_MR2021_Assignment_<assignment_number>.zip``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7adba5d",
   "metadata": {},
   "source": [
    "# Set Up\n",
    "\n",
    "We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment. All assignments will be python based, hence familiarising yourself with Python is essential.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9255b81d",
   "metadata": {},
   "source": [
    "## Setting up Anaconda environment (Recommended)\n",
    "\n",
    "1. Install Anaconda or Miniconda from [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html) depending on your requirements.\n",
    "2. Now simply run `conda env create -f environment.yml` in the current folder to create an environment `mr_assignment1` (`environment.yml` can be found in `misc/`).\n",
    "3. Activate it using `conda activate mr_assignment1`.\n",
    "\n",
    "## Setting up Virtual environment using venv\n",
    "\n",
    "You can also set up a virtual environment using venv\n",
    "\n",
    "1. Run `sudo apt-get install python3-venv` from command line.\n",
    "2. `python3 -m venv ~/virtual_env/mr_assignment1`. (you can set the environment path to anything)\n",
    "3. `source ~/virtual_env/mr_assignment1/bin/activate`\n",
    "4. `pip3 install -r requirements.txt` from the current folder (`requirements.txt` can be found in `misc/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1ef48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ac5cb",
   "metadata": {},
   "source": [
    "# 1. Getting started with Open3D\n",
    "\n",
    "Open3D is an open-source library that deals with 3D data, such as point clouds, mesh. We'll be using Open3D frequently as we work with point clouds. Let's start with something simple:\n",
    "\n",
    "<img src=\"misc/bunny.jpg\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "1. Read the Stanford Bunny file (in `data/`) given to you and visualise it using Open3D.\n",
    "2. Convert the mesh to a point cloud and change the colour of points.\n",
    "3. Set a predefined viewing angle (using Open3D) for visualization and display the axes while plotting.\n",
    "4. Scale, Transform, and Rotate the rabbit (visualise after each step).\n",
    "5. Save the point cloud as bunny.pcd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521652fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "PointCloud with 35947 points.\n"
     ]
    }
   ],
   "source": [
    "# 1. Read the Stanford Bunny file \n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import copy\n",
    "\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(\"/home/rishabh/Downloads/codes/bunny.ply\")\n",
    "print(pcd)\n",
    "mesh = o3d.geometry.TriangleMesh.create_coordinate_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe9b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert the mesh to a point cloud\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf8b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Set a predefined viewing angle and display the axes \n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)\n",
    "coordinates = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=np.array([0., 0., 0.]))\n",
    "vis.add_geometry(coordinates)\n",
    "vis_cntrl = ctr = vis.get_view_control()\n",
    "ctr.change_field_of_view(step=60)\n",
    "vis.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af28466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Scale\n",
    "pcd_scale = copy.deepcopy(pcd).translate((0.10,0.10,0.10), relative=False) # translating for better visulization  / center variable can also be changed \n",
    "pcd_scale.scale(5 , center=(0,0,0))\n",
    "o3d.visualization.draw_geometries([pcd, pcd_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f393cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Transform\n",
    "pcd_translate = copy.deepcopy(pcd).translate((0.10,0.10,0.10), relative=False)\n",
    "o3d.visualization.draw_geometries([pcd, pcd_translate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e9f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Rotate\n",
    "pcd_rotate = copy.deepcopy(pcd).translate((0.10,0.10,0.10), relative=False) # translating for better visulization  / center variable can also be changed \n",
    "R = pcd.get_rotation_matrix_from_xyz((np.pi/2,0,np.pi/4))\n",
    "pcd_rotate.rotate(R, center=(0,0,0))\n",
    "o3d.visualization.draw_geometries([pcd, pcd_rotate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741ca281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color change\n",
    "pcd.paint_uniform_color([1, 0.706, 0])\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f136563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Save the point cloud as bunny.pcd.\n",
    "o3d.io.write_point_cloud(\"bunny.pcd\", pcd )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a213a8f",
   "metadata": {},
   "source": [
    "# 2. Transformations and representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4dffe",
   "metadata": {},
   "source": [
    "## a) Euler angles\n",
    "1. Write a function that returns a rotation matrix given the angles $\\alpha$, $\\beta$, and $\\gamma$ in radians (X-Y-Z)\n",
    "\n",
    "2. Solve for angles using ```fsolve from scipy``` for three initializations of your choice and compare.\n",
    "$$M(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0.26200263 & -0.19674724 & 0.944799 \\\\0.21984631 & 0.96542533 & 0.14007684 \\\\\n",
    "    -0.93969262 & 0.17101007 & 0.29619813\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$N(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0 & -0.173648178 &  0.984807753 \\\\0 & 0.984807753 & 0.173648178 \\\\\n",
    "    -1 & 0 & 0\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "3. What is a Gimbal lock? \n",
    "\n",
    "4. Show an example where a Gimbal lock occurs and visualize the Gimbal lock on the given bunny point cloud. You have to show the above by **animation** (cube rotating along each axis one by one).\n",
    "    - *Hint: Use Open3D's non-blocking visualization and discretize the rotation to simulate the animation. For example, if you want to rotate by $30^{\\circ}$ around a particular axis, do in increments of $5^{\\circ}$ 6 times to make it look like an animation.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1297c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.12323400e-17  1.00000000e+00  6.12323400e-17]\n",
      " [ 0.00000000e+00  6.12323400e-17 -1.00000000e+00]\n",
      " [-1.00000000e+00  6.12323400e-17  3.74939946e-33]]\n"
     ]
    }
   ],
   "source": [
    "#1. Write a function that returns a rotation matrix given the angles ùõº, ùõΩ, and ùõæ in radians (X-Y-Z)\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "alpha_in = math.radians(90) #X\n",
    "beta_in = math.radians(90)  #Y\n",
    "gamma_in = math.radians(0) #Z\n",
    "s =math.sin\n",
    "c= math.cos\n",
    "def calculate_R( angles):\n",
    "  alpha = angles[0]\n",
    "  beta = angles[1]\n",
    "  gamma = angles[2]\n",
    "  R_x = np.array( [ [ 1 , 0 , 0 ] ,\n",
    "                   [ 0 , c(alpha) , -s(alpha) ]  , \n",
    "                   [0 , s(alpha) , c(alpha)]])\n",
    "    \n",
    "  R_y = np.array( [ [ c(beta) , 0 , s(beta) ] ,\n",
    "                   [ 0 ,1 ,0 ] ,\n",
    "                   [ -s(beta) , 0 , c(beta)]])\n",
    "  R_z = np.array( [ [  c(gamma) , -s(gamma) , 0 ] , \n",
    "                   [s(gamma) , c(gamma) , 0 ] ,\n",
    "                   [0 ,0, 1]]  )\n",
    "  R = R_z@R_y@R_x\n",
    "\n",
    "  return R\n",
    "\n",
    "angles = np.array( [alpha_in, beta_in, gamma_in]) # X, Y, Z\n",
    "R = calculate_R(angles)\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b0b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Actual Output  = [29.9999986  69.99999971 39.99999858]\n",
      "  Output in the least form  [29.999998599581893, 69.99999971020256, 39.999998580206736]\n",
      " Verification of Output = [30.00000046 70.00000021 40.00000028]\n",
      " *************************\n",
      " Actual Output  = [389.99999822  69.99999974 399.9999986 ]\n",
      "  Output in the least form  [29.999998220413737, 69.999999744902, 39.999998600052024]\n",
      " Verification of Output = [30.00000046 70.00000021 40.00000028]\n",
      " *************************\n",
      " Actual Output  = [29.99999791 69.99999925 39.99999847]\n",
      "  Output in the least form  [29.99999790898721, 69.99999925223901, 39.999998467017726]\n",
      " Verification of Output = [30.00000046 70.00000021 40.00000028]\n",
      " *************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh/.local/lib/python3.8/site-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# 2a. Solve for angles using fsolve from scipy \n",
    "# For M matrix\n",
    "\n",
    "from scipy.optimize import fsolve\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "alpha_init = 50*np.pi/180 \n",
    "beta_init = 100*np.pi/180  \n",
    "gamma_init = 0*np.pi/180 \n",
    "sq = math.sqrt\n",
    "euler_angles = np.array( [ alpha_init , beta_init ,gamma_init ]) # rotation in X, Y, Z\n",
    "\n",
    "target_R = np.array( [ [  0.26200263 , -0.19674724 , 0.944799 ] ,\n",
    "\t\t[0.21984631  , 0.96542533 , 0.14007684 ] , \n",
    "\t\t[ -0.93969262 , 0.17101007 , 0.29619813 ] ])\n",
    "\n",
    "v1 = np.array( [ 1,1,1 ] )\n",
    "v1 = v1/np.linalg.norm( v1)\n",
    "target_v1 = target_R@v1\n",
    "\n",
    "v2 = np.array( [ 1,1,0 ] )\n",
    "v2 = v2/np.linalg.norm( v2)\n",
    "target_v2 = target_R@v2\n",
    "\n",
    "v3 = np.array( [ 0,1,0 ] )\n",
    "v3 = v3/np.linalg.norm( v3)\n",
    "target_v3 = target_R@v3\n",
    "\n",
    "def determine_euler_angles( angles):\n",
    "\talpha = angles[0]  # X\n",
    "\tbeta = angles[1] #Y\n",
    "\tgamma = angles[2] #Z\n",
    "\ts = math.sin\n",
    "\tc = math.cos\n",
    "\n",
    "\tR_x = np.array( [ [ 1,0 ,0  ]  ,\n",
    "\t\t\t\t\t   [ 0 , c(alpha) , -s(alpha)] , \n",
    "\t\t\t\t\t   [ 0 , s(alpha) , c(alpha)] ]  )\n",
    "\tR_y = np.array( [ [ c(beta),0 ,s(beta)  ]  ,\n",
    "\t\t\t\t\t   [ 0 , 1 , 0] , \n",
    "\t\t\t\t\t   [ -s(beta) , 0 , c(beta)] ]  )\n",
    "\tR_z = np.array( [ [ c(gamma) , -s(gamma) , 0 ] , \n",
    "\t\t\t\t\t\t[s(gamma) , c(gamma) , 0] , \n",
    "\t\t\t\t\t\t[0 ,0 ,1] ] )\n",
    "\n",
    "\tR = R_z@R_y@R_x\n",
    "\n",
    "\tcurr_v1 = R@v1 \n",
    "\tcurr_v2 = R@v2 \n",
    "\tcurr_v3 = R@v3 \n",
    "\n",
    "\tresidual_x1 = np.linalg.norm( curr_v1[0] - target_v1[0])\n",
    "\tresidual_y1 = np.linalg.norm(curr_v1[1] - target_v1[1])\n",
    "\tresidual_z1 = np.linalg.norm(curr_v1[2] - target_v1[2])\n",
    "\t# print(residual_x , residual_y , residual_z )\n",
    "\n",
    "\tresidual_x2 = np.linalg.norm( curr_v2[0] - target_v2[0])\n",
    "\tresidual_y2 = np.linalg.norm(curr_v2[1] - target_v2[1])\n",
    "\tresidual_z2 = np.linalg.norm(curr_v2[2] - target_v2[2])\n",
    "\n",
    "\tresidual_x3 = np.linalg.norm( curr_v3[0] - target_v3[0])\n",
    "\tresidual_y3 = np.linalg.norm(curr_v3[1] - target_v3[1])\n",
    "\tresidual_z3 = np.linalg.norm(curr_v3[2] - target_v3[2])\n",
    "\n",
    "\treturn residual_x1+residual_x2+residual_x3 , residual_y1+residual_y2+residual_y3 , residual_z1+residual_z2+residual_z3\n",
    "\n",
    "for i in range(3):\n",
    "\tres_angles = fsolve(determine_euler_angles , euler_angles*(i ))\n",
    "\tprint(\" Actual Output  = \" + str( res_angles*180/np.pi))\n",
    "\n",
    "\tres_angles = res_angles*180/np.pi\n",
    "\tres_angles_alpha  =   (res_angles[0]/360 - int(res_angles[0]/360 )  )*360\n",
    "\tres_angles_beta  =   (res_angles[1]/360 - int(res_angles[1]/360 ) )*360\n",
    "\tres_angles_gamma  =   (res_angles[2]/360 - int(res_angles[2]/360 ) )*360\n",
    "\n",
    "\tleast_Res_angle = [ res_angles_alpha , res_angles_beta , res_angles_gamma]\n",
    "\tprint(\"  Output in the least form  \" + str( least_Res_angle))\n",
    "\n",
    "\tM = R.from_matrix( [ [  0.26200263 , -0.19674724 , 0.944799 ] ,\n",
    "\t\t[0.21984631  , 0.96542533 , 0.14007684 ] , \n",
    "\t\t[ -0.93969262 , 0.17101007 , 0.29619813 ] ])\n",
    "\n",
    "\tN = R.from_matrix( [ [  0 , -0.173648178 , 0.984807753  ]  , \n",
    "\t[ 0 , 0.96542533 ,  0.14007684 ] , \n",
    "\t[ -1  , 0 , 0 ]  ])\n",
    "\n",
    "\tprint( \" Verification of Output = \"  + str( M.as_euler('xyz', degrees=True))) \n",
    "\tprint(\" *************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d656bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Actual Output  = [35.74907477 90.76606127 45.27806769]\n",
      "  Output in the least form  [35.74907477427767, 90.76606126568731, 45.27806768864778]\n",
      " Verification of Output = [-64.54086106  88.87904355 -55.4591339 ]\n",
      " *************************\n",
      " Actual Output  = [82.93814462 90.66720953 92.86738765]\n",
      "  Output in the least form  [82.93814462187515, 90.66720953390856, 92.86738764752302]\n",
      " Verification of Output = [-64.54086106  88.87904355 -55.4591339 ]\n",
      " *************************\n",
      " Actual Output  = [ 92.25823606  90.69028314 102.25051855]\n",
      "  Output in the least form  [92.25823606224132, 90.69028313681312, 102.2505185499182]\n",
      " Verification of Output = [-64.54086106  88.87904355 -55.4591339 ]\n",
      " *************************\n"
     ]
    }
   ],
   "source": [
    "# 2b. Solve for angles using fsolve from scipy \n",
    "# For N matrix\n",
    "\n",
    "from scipy.optimize import fsolve\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "alpha_init = np.pi/180 \n",
    "beta_init = np.pi/180  \n",
    "gamma_init = np.pi/180 \n",
    "sq = math.sqrt\n",
    "\n",
    "euler_angles = np.array( [ alpha_init , beta_init ,gamma_init ]) # rotation in X, Y, Z\n",
    "target_R = np.array( [ [  0 , -0.173648178 , 0.984807753  ]  , \n",
    "\t[ 0 , 0.96542533 ,  0.14007684 ] , \n",
    "\t[ -1  , 0 , 0 ]  ] )\n",
    "\n",
    "v1 = np.array( [ 1,1,1 ] )\n",
    "v1 = v1/np.linalg.norm( v1)\n",
    "target_v1 = target_R@v1\n",
    "\n",
    "v2 = np.array( [ 1,1,0 ] )\n",
    "v2 = v2/np.linalg.norm( v2)\n",
    "target_v2 = target_R@v2\n",
    "\n",
    "v3 = np.array( [ 0,1,0 ] )\n",
    "v3 = v3/np.linalg.norm( v3)\n",
    "target_v3 = target_R@v3\n",
    "\n",
    "def determine_euler_angles( angles):\n",
    "\n",
    "\talpha = angles[0]  # X\n",
    "\tbeta = angles[1] #Y\n",
    "\tgamma = angles[2] #Z\n",
    "\ts = math.sin\n",
    "\tc = math.cos\n",
    "\n",
    "\tR_x = np.array( [ [ 1,0 ,0  ]  ,\n",
    "\t\t\t\t\t   [ 0 , c(alpha) , -s(alpha)] , \n",
    "\t\t\t\t\t   [ 0 , s(alpha) , c(alpha)] ]  )\n",
    "\tR_y = np.array( [ [ c(beta),0 ,s(beta)  ]  ,\n",
    "\t\t\t\t\t   [ 0 , 1 , 0] , \n",
    "\t\t\t\t\t   [ -s(beta) , 0 , c(beta)] ]  )\n",
    "\tR_z = np.array( [ [ c(gamma) , -s(gamma) , 0 ] , \n",
    "\t\t\t\t\t\t[s(gamma) , c(gamma) , 0] , \n",
    "\t\t\t\t\t\t[0 ,0 ,1] ] )\n",
    "\n",
    "\tR = R_z@R_y@R_x\n",
    "\tcurr_v1 = R@v1 \n",
    "\tcurr_v2 = R@v2 \n",
    "\tcurr_v3 = R@v3 \n",
    "\n",
    "\tresidual_x1 = np.linalg.norm( curr_v1[0] - target_v1[0])\n",
    "\tresidual_y1 = np.linalg.norm(curr_v1[1] - target_v1[1])\n",
    "\tresidual_z1 = np.linalg.norm(curr_v1[2] - target_v1[2])\n",
    "\t# print(residual_x , residual_y , residual_z )\n",
    "\n",
    "\tresidual_x2 = np.linalg.norm( curr_v2[0] - target_v2[0])\n",
    "\tresidual_y2 = np.linalg.norm(curr_v2[1] - target_v2[1])\n",
    "\tresidual_z2 = np.linalg.norm(curr_v2[2] - target_v2[2])\n",
    "\n",
    "\tresidual_x3 = np.linalg.norm( curr_v3[0] - target_v3[0])\n",
    "\tresidual_y3 = np.linalg.norm(curr_v3[1] - target_v3[1])\n",
    "\tresidual_z3 = np.linalg.norm(curr_v3[2] - target_v3[2])\n",
    "\n",
    "\treturn residual_x1+residual_x2+residual_x3 , residual_y1+residual_y2+residual_y3 , residual_z1+residual_z2+residual_z3\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "\tres_angles = fsolve(determine_euler_angles , euler_angles*(i ))\n",
    "\tprint(\" Actual Output  = \" + str( res_angles*180/np.pi))\n",
    "\tres_angles = res_angles*180/np.pi\n",
    "\tres_angles_alpha  =   (res_angles[0]/360 - int(res_angles[0]/360 )  )*360\n",
    "\tres_angles_beta  =   (res_angles[1]/360 - int(res_angles[1]/360 ) )*360\n",
    "\tres_angles_gamma  =   (res_angles[2]/360 - int(res_angles[2]/360 ) )*360\n",
    "\tleast_Res_angle = [ res_angles_alpha , res_angles_beta , res_angles_gamma]\n",
    "\tprint(\"  Output in the least form  \" + str( least_Res_angle))\n",
    "\n",
    "\tN = R.from_matrix( [ [  0 , -0.173648178 , 0.984807753  ]  , \n",
    "\t[ 0 , 0.96542533 ,  0.14007684 ] , \n",
    "\t[ -1  , 0 , 0 ]  ])\n",
    "\n",
    "\tprint( \" Verification of Output = \"  + str( N.as_euler('xyz', degrees=True))) \n",
    "\tprint(\" *************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75cb3df",
   "metadata": {},
   "source": [
    "3. Gimbal lock\\\n",
    "When two rotational axes are completely aligned (or parallel) with each other it leads to the gimbal lock configuration, where 1DOF is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a92dccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Complete X rotation 0.5235987755982988\n",
      " Complete Y rotation 0.6981317007977318\n",
      " Complete Z rotation 1.0471975511965976\n",
      " *********************** \n",
      " COmpleted the iteration \n",
      " *********************** \n",
      " Complete X rotation 0.5235987755982988\n",
      " Complete Y rotation 1.5707963267948966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_286642/3783007639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[0mR_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbunny\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rotation_matrix_from_axis_angle\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0maxis_new_after_x_and_y_rotation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresolution\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mperform_rotation\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mR_z\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Complete Z rotation \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_geometries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_286642/3783007639.py\u001b[0m in \u001b[0;36mperform_rotation\u001b[0;34m(R, resolution)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mangles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrotation_sequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4. visualize the Gimbal lock on the given bunny point cloud\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from scipy.linalg import expm, sinm, cosm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.spatial.transform import Slerp\n",
    "import copy\n",
    "sq = math.sqrt\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "bunny = o3d.io.read_point_cloud(\"/home/rishabh/Downloads/codes/bunny.ply\")\n",
    "# vis.add_geometry(bunny)\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame( size=0.2, origin=[0, 0, 0] )\n",
    "# vis.add_geometry(coordinate_frame)\n",
    "\n",
    "coordinate_frame_copy = copy.deepcopy(coordinate_frame)\n",
    "# vis.add_geometry(coordinate_frame_copy)\n",
    "\n",
    "resolution = 30\n",
    "rad_angle = 0 \n",
    "sq = math.sqrt\n",
    "rotation_sequence = np.array( [ [  30 , 40  , 60   ]  ,  ## Initial rotation demonstration without gimbal lock\n",
    "                                 [ 30 , 90 , 360  ]  ,  ## Gimbal Lock \n",
    "                                 [60, -90, 360 ] ]) \n",
    "\n",
    "def perform_rotation( R, resolution):\n",
    "  for increment in range(resolution):\n",
    "    bunny.rotate(R)\n",
    "    # coordinate_frame_copy.rotate(R)\n",
    "    vis.update_geometry(bunny)\n",
    "    # vis.update_geometry(coordinate_frame_copy)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    time.sleep(0.1)    \n",
    "\n",
    "for angles in rotation_sequence:\n",
    "  vis.add_geometry(bunny)\n",
    "  vis.add_geometry(coordinate_frame)\n",
    "  vis.add_geometry(coordinate_frame_copy)\n",
    "\n",
    "  alpha =  angles[0]*np.pi/180 # X\n",
    "  beta = angles[1]*np.pi/180 # Y\n",
    "  gamma = angles[2]*np.pi/180 # Z\n",
    "  euler_angles = np.array( [ alpha , beta ,gamma ]) # rotation in X, Y, Z\n",
    "\n",
    "  # we will perform rotations in the sequence X, Y, Z\n",
    "  original_axis = np.array( [ [ 1 , 0 , 0 ] ,  #X\n",
    "                            [0 ,1, 0]  ,  #Y\n",
    "                              [0,0,1] ]) # Z\n",
    "  # rotate around x axis \n",
    "\n",
    "  R_x = bunny.get_rotation_matrix_from_axis_angle( original_axis[0].T*(alpha/resolution) )\n",
    "  if alpha!= 0 :\n",
    "   perform_rotation( R_x , resolution)\n",
    "  print(\" Complete X rotation \" + str(alpha))\n",
    "\n",
    "  R_after_rotation_around_x = bunny.get_rotation_matrix_from_xyz( ( alpha , 0 , 0 ))\n",
    "\n",
    "  axis_new_after_x_rotation = np.dot( R_after_rotation_around_x , original_axis)\n",
    "  # rotate around y axis \n",
    "  time.sleep(2)\n",
    "\n",
    "  R_y = bunny.get_rotation_matrix_from_axis_angle( axis_new_after_x_rotation[1].T*(beta/resolution) )\n",
    "  if beta !=0 :\n",
    "    perform_rotation( R_y , resolution)\n",
    "  R_after_rotation_around_x_and_y = bunny.get_rotation_matrix_from_xyz( ( alpha , beta , 0 ))\n",
    "  axis_new_after_x_and_y_rotation = np.dot( R_after_rotation_around_x_and_y , original_axis)\n",
    "\n",
    "  print(\" Complete Y rotation \"  + str(beta))\n",
    "  # rotate around z axis \n",
    "  time.sleep(2)\n",
    "\n",
    "  R_z = bunny.get_rotation_matrix_from_axis_angle( axis_new_after_x_and_y_rotation[2].T*gamma/resolution )\n",
    "  if gamma != 0 :\n",
    "    perform_rotation( R_z , resolution)\n",
    "  print(\" Complete Z rotation \" +str(gamma) )\n",
    "  vis.clear_geometries()\n",
    "  time.sleep(5)\n",
    "  print(\" *********************** \")\n",
    "  print(\" COmpleted the iteration \")\n",
    "  print(\" *********************** \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d69a50",
   "metadata": {},
   "source": [
    "## b) Quaternions\n",
    "\n",
    "1. What makes Quaternions popular in graphics? \n",
    "2. Convert a rotation matrix to quaternion and vice versa. Do not use inbuilt libraries for this question.\n",
    "3. Perform matrix multiplication of two $\\mathcal{R}_{3 \\times 3}$ rotation matrices and perform the same transformation in the quaternion space. Verify if the final transformation obtained in both the cases are the same.\n",
    "4. Try to interpolate any 3D model (cube / bunny / not sphere obviously!!) between two rotation matrices and visualize!\n",
    "\n",
    "The above questions require you to **code your own functions** and **only verify** using inbuilt functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb74c87",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "1.Quaternions are popular because\\\n",
    "a) Quaternion representaion can overcome the gimbal lock problem.\\\n",
    "b) It is more memory efficient, quaternion require 4 parameters to explain arotation where as a rotation matrix requires 9 elements.\\\n",
    "c) They are unique and euler angles are not.\\\n",
    "d) Provides a seamless way to interpolate between two 3D orientations, thatlacks the ambiguities of Euler angles and issues related to the normaliza-tion and numerical instabilities of the rotation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8ca4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47570143  0.86355231 -0.16728885]\n",
      " [-0.49332001  0.10446427 -0.60190545]\n",
      " [-0.72824688  0.49332001  0.47570143]]\n"
     ]
    }
   ],
   "source": [
    "#2 Rotation matrix to quaternion\n",
    "\n",
    "import numpy as np\n",
    "def Quaternion_to_RotationMatrix(q):\n",
    "    n = 1/np.sqrt(q[0]*q[0] + q[1]*q[1] + q[2]*q[2] + q[3]*q[3]) #Normalize\n",
    "    qw = q[0]*n\n",
    "    qx = q[1]*n\n",
    "    qy = q[2]*n\n",
    "    qz = q[3]*n\n",
    "    \n",
    "    RotationMatrix = np.array([[1 - 2*(qz*qz + qy * qy) , -2*(qz*qw - qy*qx), 2*(qy*qw + qz*qx)],\n",
    "                           [2*(qx*qy + qw*qz),  1 - 2*(qz*qz + qx*qx) , 2*(qy*qy - qx*qw)],\n",
    "                           [2*(qx*qz - qw*qy), 2*(qy*qz + qw*qx), 1 - 2*(qy*qy + qx*qx)]])\n",
    "                            \n",
    "    return RotationMatrix\n",
    "\n",
    "q = np.array([0.7, 0.462, 0.191, -0.462])\n",
    "R = Quaternion_to_RotationMatrix(q)\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06348c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Transformed Quaternion  = [ 0.71691477  0.38192318  0.19561532 -0.47316375]\n",
      " Original Quaternion  = [ 0.7    0.462  0.191 -0.462]\n",
      "Both quaternion are not exactly same\n"
     ]
    }
   ],
   "source": [
    "#2 Quaternion to Rotation matrix\n",
    "# https://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/\n",
    "# https://d3cw3dd2w32x2b.cloudfront.net/wp-content/uploads/2015/01/matrix-to-quat.pdf\n",
    "# http://what-when-how.com/advanced-methods-in-computer-graphics/quaternions-advanced-methods-in-computer-graphics-part-3/\n",
    "\n",
    "def RotationMatrix_to_Quaternion(R):\n",
    "    m00 = R[0,0]\n",
    "    m01 = R[0,1]\n",
    "    m02 = R[0,2]\n",
    "    m10 = R[1,0]\n",
    "    m11 = R[1,1]\n",
    "    m12 = R[1,2]\n",
    "    m20 = R[2,0]\n",
    "    m21 = R[2,1]\n",
    "    m22 = R[2,2]\n",
    "    \n",
    "    trace = m00 + m11 + m22\n",
    "    if(trace > 0):\n",
    "        sq = np.sqrt(trace + 1)*2\n",
    "        qw = 0.25*sq\n",
    "        qx = (m21 - m12)/sq\n",
    "        qy = (m02 - m20)/sq\n",
    "        qz = (m10 - m01)/sq\n",
    "        \n",
    "    elif(m00 > m11 and m00 > m22):\n",
    "        sq = np.sqrt(1 + m00 - m11 - m22)*2\n",
    "        qw = (m21 - m12)/sq\n",
    "        qx = 0.25*sq\n",
    "        qy = (m01 + m10)/sq\n",
    "        qz = (m02 + m20)/sq\n",
    "        \n",
    "    elif(m11 > m22):\n",
    "        sq = np.sqrt(1 + m11 - m00 - m22)*2\n",
    "        qw = (m02 - m20)/sq\n",
    "        qx = (m01 + m10)/sq\n",
    "        qy = 0.25*sq\n",
    "        qz = (m12 + m21)/sq\n",
    "        \n",
    "    else:\n",
    "        sq = np.sqrt(1 + m22 - m00 - m11)*2\n",
    "        qw = (m10 - m01)/sq\n",
    "        qx = (m02 + m20)/sq\n",
    "        qy = (m12 + m21)/sq\n",
    "        qz = 0.25*sq\n",
    "\n",
    "    q = np.array([qw, qx,qy,qz])\n",
    "    return q\n",
    "\n",
    "q1 = (RotationMatrix_to_Quaternion(R))\n",
    "print(\" Transformed Quaternion  = \" + str(q1))\n",
    "print(\" Original Quaternion  = \" + str(q))\n",
    "print(\"Both quaternion are not exactly same\")\n",
    "# R1 = Quaternion_to_RotationMatrix(q1)\n",
    "# print(R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7458a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.733 0.462 0.191 0.462]\n",
      "[0.73275896 0.49714411 0.19093719 0.46184808]\n"
     ]
    }
   ],
   "source": [
    "#  3. Verify if the final transformation obtained by R matrix multiplication and Quaternion\n",
    "\n",
    "quat_1 = np.array([0.733, 0.462 , 0.191, 0.462])\n",
    "quat_2 = np.array([1, 0 , 0, 0])\n",
    "\n",
    "rot_1 = Quaternion_to_RotationMatrix(quat_1)\n",
    "rot_2 = Quaternion_to_RotationMatrix(quat_2)\n",
    "\n",
    "# quaternion multiplication\n",
    "quat0 = quat_1[0]*quat_2[0] - quat_1[1]*quat_2[1] - quat_1[2]*quat_2[2] - quat_1[3]*quat_2[3]\n",
    "quat1 = quat_1[0]*quat_2[1] + quat_1[1]*quat_2[0] - quat_1[2]*quat_2[3] + quat_1[3]*quat_2[2]\n",
    "quat2 = quat_1[0]*quat_2[2] + quat_1[1]*quat_2[3] + quat_1[2]*quat_2[0] - quat_1[3]*quat_2[1]\n",
    "quat3 = quat_1[0]*quat_2[3] - quat_1[1]*quat_2[2] + quat_1[2]*quat_2[1] + quat_1[3]*quat_2[0]\n",
    "quat = np.array([quat0,quat1,quat2,quat3])\n",
    "\n",
    "rot = np.dot(rot_2,rot_1)   #not commutative\n",
    "quat_conversion = RotationMatrix_to_Quaternion(rot)\n",
    "\n",
    "print(quat)\n",
    "print(quat_conversion)\n",
    "\n",
    "#note: R matrix by [- quaternion] = R matrix by [quaternion]\n",
    "\n",
    "# SOLUTION:- Both are not exactly same. Transforming a Quaternion to Rotation Matrix and again changing \n",
    "# the same Rotation matrix back to Quaternion will not be exactly same as original one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f23c58",
   "metadata": {},
   "source": [
    "#4 . Interpolate any 3D model between two rotation matrices\n",
    "\n",
    "For this question we present two methods \n",
    "\n",
    "1) Here we obtain the logarithmic map of the corresponding rotation matrix, and we divide the resulting rotation   into uniform steps and execute the given rotations step by step. This method although arrives at the final rotation matrix, the interpolation is not smooth. \n",
    "\n",
    "2) SLERP: scipy library provides a convinent method to perform rotation interpolation using quaternions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feee0e00",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_286642/2566032325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m## Interpolation using SLERP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4. Interpolate any 3D model between two rotation matrices and visualize\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import math\n",
    "sq = math.sqrt\n",
    "import time\n",
    "from scipy.linalg import expm, sinm, cosm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.spatial.transform import Slerp\n",
    "\n",
    "init_v = np.array([ 0 ,1,0])\n",
    "\n",
    "# R_init = np.identity(3)\n",
    "'''\n",
    "R_init = np.array( [ [ 1, 0, 0 ] , \n",
    "                        [0,1,0] , \n",
    "                          [0,0,1]   ])\n",
    "\n",
    "R_final = np.array([ [ 0 , 1 , 0  ] , \n",
    "                      [ 0 ,0 ,1  ], \n",
    "                      [ 1 , 0 , 0]   ])\n",
    "\n",
    "R_mid = np.array([ [ 1 , 0 , 0  ] , \n",
    "                      [ 0 ,0 ,1  ], \n",
    "                      [ 0 , 1 , 0]   ])\n",
    "\n",
    "'''\n",
    "key_rots = R.random(2, random_state=2342345) # generate two quaternions \n",
    "R_init = key_rots[0].as_matrix()\n",
    "R_final = key_rots[1].as_matrix()\n",
    "\n",
    "def logarithmic_map( R):\n",
    "    phi  = math.acos( (np.trace(R) -1)/2  )\n",
    "    # print(phi)\n",
    "    u = (R - R.T)/(2*math.sin(phi))\n",
    "#     print(u)\n",
    "    U = np.array( [   u[2][1] , u[0][2] , u[1][0]   ] )\n",
    "    return phi , U\n",
    "\n",
    "def get_delta_SO3(time_t):\n",
    "    w = U_final #np.array( [ 1,0,0  ])\n",
    "    w = w*time_t\n",
    "    so3 = np.array( [  [ 0, -w[2] , w[1]  ]  , \n",
    "                        [ w[2] , 0 , -w[0]  ] ,\n",
    "                        [-w[1] , w[0] , 0 ]   ]  )\n",
    "    # print(so3)\n",
    "    del_SO3 = expm( so3)\n",
    "    return del_SO3\n",
    "\n",
    "def get_rotation_matrix_at_time_t( R_t_minus_1 , time_t):\n",
    "    R_delta_t = get_delta_SO3(time_t)\n",
    "    # R_t =  np.matmul(  R_t_minus_1 , R_delta_t )  #R_t_minus_1@R_delta_t\n",
    "    # print( R_delta_t)\n",
    "    return R_delta_t\n",
    "\n",
    "# phi_int , U_init = logarithmic_map( R_init)\n",
    "phi_final , U_final = logarithmic_map( R_final)\n",
    "\n",
    "# Create Open3d visualization window\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "# create sphere geometry\n",
    "bunny =  o3d.io.read_point_cloud(\"/home/rishabh/Downloads/codes/bunny.ply\")\n",
    " #o3d.geometry.TriangleMesh.create_box(width=0.2, height=0.2, depth=0.5 ) #o3d.geometry.TriangleMesh.create_cube()\n",
    "vis.add_geometry(bunny)\n",
    "\n",
    "# create coordinate frame\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame()\n",
    "vis.add_geometry(coordinate_frame)\n",
    "\n",
    "# R_init = np.identity(3)\n",
    "R = R_init\n",
    "curr_tf = R\n",
    "prev_tf = None\n",
    "step = 0\n",
    "resolution = phi_final/20\n",
    "\n",
    "for i in range( 20):\n",
    "    time_t = i*resolution\n",
    "    # return sphere1 to original position (0,0,0)\n",
    "    R = curr_tf\n",
    "    step +=1\n",
    "#     print(step)\n",
    "    if prev_tf is not None:\n",
    "        bunny.transform(np.linalg.inv(prev_tf))\n",
    "    # transform bazed on curr_z tf\n",
    "    curr_tf = get_rotation_matrix_at_time_t(R , time_t)\n",
    "    # sphere1.transform(curr_tf)\n",
    "    bunny.rotate(curr_tf)\n",
    "#     print(curr_tf)\n",
    "    vis.update_geometry(bunny)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "## Interpolation using SLERP \n",
    "key_times = [0, 3]\n",
    "# key_times = np.arange( 0,10, 0.1)\n",
    "slerp = Slerp(key_times, key_rots)\n",
    "times = np.arange( 0,3, 0.20)\n",
    "interp_rots = slerp(times)\n",
    "R_interpolate = interp_rots.as_matrix()\n",
    "vis.create_window()\n",
    "vis.add_geometry(bunny)\n",
    "vis.add_geometry(coordinate_frame)\n",
    "\n",
    "for Rot in ( R_interpolate):\n",
    "    bunny.rotate(Rot)\n",
    "    vis.update_geometry(bunny)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831fd1c8",
   "metadata": {},
   "source": [
    "## c) Exponential maps (Bonus)\n",
    "\n",
    "1. What is the idea behind exponential map representation of rotation matrices?\n",
    "2. Perform matrix exponentiation and obtain the rotation matrix to rotate a vector $P$ around $\\omega$ for $\\theta$ seconds.\n",
    "$$\n",
    "\\omega = \\begin{bmatrix}2 \\\\ 1 \\\\ 15 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta = 4.1364\n",
    "$$\n",
    "\n",
    "3. Compute the logarithmic map (SO(3) to so(3)) of the rotation matrix to obtain the rotation vector and the angle of rotation\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.1 &  -0.9487 & 0.3 \\\\\n",
    "0.9487 & 0.  & -0.3162 \\\\\n",
    "0.3   &  0.3162  & 0.9 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "You can use inbuilt libraries **only to verify** your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b445540",
   "metadata": {},
   "source": [
    "### Solution:-\n",
    "1. The idea behind exponential map representation of rotation matrices.\n",
    "\n",
    "The Rotation matrices are not closed under the operation of addition or subtraction, hence the generic way of differentiation cannot defined for SO(3) groups. The exponential map allows us to properly define derivatives, perturbations, and velocities, and to manipulate them.  \n",
    "\n",
    "Furthermore, it is possible to define\n",
    "a continuous trajectory or path $r(t)$ in SO(3) that continuously rotates the rigid body from its initial orientation, r(0), to its current orientation, $r(t)$. Being continuous, it is legitimate to investigate the time-derivatives of such transformations. \n",
    "\n",
    "Exponential maps require only two quantities for a rotation parametrization, ie a unit vector \"$e$\" to represent the direction of an axis of rotation and an angle \"$\\theta$\" denotes magnititude of rotation about the axis.\n",
    "\n",
    "#Ref: https://www.cs.cmu.edu/~spiff/moedit99/expmap.pdf \\\n",
    "#Ref : https://arxiv.org/pdf/1711.02508.pdf  equation 80 , 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "748c2d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99506737  0.09902323 -0.00594386]\n",
      " [-0.09893593  0.99500189  0.01352466]\n",
      " [ 0.00725341 -0.01286989  0.99989087]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Perform matrix exponentiation\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import expm, sinm, cosm\n",
    "w = np.array( [ 2,1,15])\n",
    "theta = 4.1364\n",
    "w_theta = w*theta\n",
    "so3 = np.array( [ [ 0 , -w_theta[2] , w_theta[1]  ] , \n",
    "                 [ w_theta[2] , 0 , -w_theta[0] ] , \n",
    "                 [ -w_theta[1] , w_theta[0] , 0 ]   ])\n",
    "\n",
    "print( expm(so3))\n",
    "#Reference : https://arxiv.org/pdf/1711.02508.pdf  equation 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60ca2b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.     -0.9487  0.    ]\n",
      " [ 0.9487  0.     -0.3162]\n",
      " [ 0.      0.3162  0.    ]]\n",
      "[0.3162, 0.0, -0.9487]\n",
      "1.5707963267948966\n"
     ]
    }
   ],
   "source": [
    "# 3. Compute the logarithmic map (SO(3) to so(3))\n",
    "\n",
    "R = np.array( [ [ 0.1 , -0.9487 , 0.3  ] , \n",
    "                [ 0.9487, 0 , -0.3162 ] , \n",
    "               [  0.3 , 0.3162 , 0.9]  ])\n",
    "\n",
    "value = (np.trace(R) -1)/2\n",
    "phi = np.arccos( value)\n",
    "\n",
    "new_matrix = (R - R.T)/(2*np.sin(phi))\n",
    "print(new_matrix)\n",
    "\n",
    "u = [ new_matrix[2][1] , new_matrix[0][2] , new_matrix[0][1]  ]\n",
    "print(u) \n",
    "print(phi)\n",
    "\n",
    "#Reference : https://arxiv.org/pdf/1711.02508.pdf  equation 80 , 81"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce4d3b",
   "metadata": {},
   "source": [
    "# 3. Data representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae9a1f6",
   "metadata": {},
   "source": [
    "## a) Octomaps\n",
    "\n",
    "1. Why is an Octomap memory efficient?\n",
    "2. When do we update an Octomap and why?\n",
    "3. When would you likely use an octomap instead of a point cloud?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67154ffe",
   "metadata": {},
   "source": [
    "### Solutions 3 (a)\n",
    "1. The octomap representation is memory efficient for the following reasons\n",
    "\n",
    "A.  Pruning mechanism:  If all children of a node are at the same state (either free or occupied) then the children are pruned and the parent is retained.This leads to elimination of redundant information and a significant decrease in the number of nodes that need to be stored.\n",
    "\n",
    "B.  OcTree Compression: This step is performed along with the pruning mechanism, the child nodes(memory) are regenerated on requirement basis i.e if a parent node is stable and the child nodes are pruned, the child nodes are regenerated only when measurements that contradict the state of inner node occur.\n",
    "\n",
    "C.  Memory-Efficient Node Implementation: the memory layout of data is as follows. For a given node, a child pointer points to an array of 8 pointers and the inner nodes additionally store pointers of their children. In additon to this each node of an octree stores the probablity of occupancy. Note that the array is allocated only if the node has chilren and is not allocated for leaves, the leaf node of octree only stores only occupancy probablity and Null for pointer to child. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd5f1f",
   "metadata": {},
   "source": [
    "### Solutions 3 (a)\n",
    "2. The update of the Octomap depends upon the present state of the node\n",
    "\n",
    "A.  Node is unknown and first observed: On observation of measurments form the sensor, the observations are continously integrated and a clamping update policy is used that defines upper and lower thresholds on the log odds value of occupancy. Once the integrated measurments cross the the necessary stable threshold the node is updated. \n",
    "\n",
    "B. Stable node updated through contradictory measurements: If all the inner nodes of a parent are stable then the nodes are pruned, only in future if measurments that contradict the present state of parent is integrated then its children are regenerated and updated accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b79b4",
   "metadata": {},
   "source": [
    "### Solutions 3 (a)\n",
    "3. Octomap can be used instead of the point cloud in the following scenarios\n",
    "\n",
    "A.  Notion  of  free  space:   Octomap  has  an  ability  to  represent  free  space,although we get information to the surface boundaries of an obstacle from point cloud it would be difficult to determine if a set of points in space isoccupied or free. Octomap provides us Full 3D model. \n",
    "\n",
    "B.  Stable Data Structure:  The data structures used to store and update themap  is  of  critical  importance.   Consider  the  situation  where  we  assigna binary (1/0 for occupied/free) label to every point in the point cloud,the look up table would be memory inefficient and difficult to accurately update.  Octomap provides for an elegant alternative with an efficient datastructure for occupancy updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e6e7d",
   "metadata": {},
   "source": [
    "## b) Signed Distance Functions\n",
    "\n",
    "1. How do we determine object surfaces using SDF?\n",
    "2. How do we aggregate views from multiple cameras? (just a general overview is fine)\n",
    "3. Which preserves details better? Voxels or SDF? Why?\n",
    "4. What‚Äôs an advantage of SDF over a point cloud?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a11bf",
   "metadata": {},
   "source": [
    "### SOLUTION\n",
    "1. For a given SDF function $\\theta(x): R^3 \\rightarrow R$. This function returns for any point $x \\in R^3 $ the  signed  distance  from   to  the surface. \\\n",
    "If $x$ is on the surface then $\\theta(x) = 0$ .\\\n",
    "Ref:- http://www.roboticsproceedings.org/rss09/p35.pdf  \\\n",
    "Note:- For discrete representations of Implicit Functions, the location of the interface ,the $\\phi(x)= 0$ zero iso-contour is interpolated from the known values of $\\phi$ at the data points using Marching Cubes algorithm.\n",
    "Ref:- http://faculty.missouri.edu/duanye/course/cs8620-spring-2017/lecture-notes/3a-implicit-geometry.pdf \n",
    "\n",
    "\n",
    "\n",
    "2. The aggregate views from multiple cameras is used for the camera motion estimation to find the affine transformations which convert the local frame's point clouds to global coordinate and integrate them into a final point cloud for a object representation.  These affine  transformation represent the movement of camera from the first frame to the last frame. \\\n",
    "Ref:- https://thesai.org/Downloads/IJARAI/Volume5No9/Paper_5-WSDF_Weighting_of_Signed_Distance_Function.pdf\n",
    "\n",
    "\n",
    "3. SDF has gradient and distance information inherently available. Voxel-based approaches do not preserve fine shape details since when rendered their normals are not smooth. SDF scale beautifully because of smooth interpolation between samples. \n",
    "\n",
    "\n",
    "4. Pointclouds are not suitable for producing smooth surfaces and there is no simple representation of free or unknown space. While in SDF, surface looks very smooth due to sub-pixel level accuracy, which giver better visualization. SDF provides us an ability to scale a 3D model. \\\n",
    "Ref:- https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e963c91",
   "metadata": {},
   "source": [
    "# References and Resources\n",
    "\n",
    "1. Gimbal locks and quaternions: https://youtu.be/YF5ZUlKxSgE\n",
    "2. Exponential map: \n",
    "    1. 3 Blue 1 Brown: https://youtu.be/O85OWBJ2ayo\n",
    "    2. Northwestern Robotics: https://youtu.be/v_KBHaG0mas\n",
    "3. Bunny ply is taken from: http://graphics.im.ntu.edu.tw/~robin/courses/cg03/model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
